---
title: What factors influence the overall rating of soccer players in the FIFA video game
author: "Yizhuo Liu, Leo Cheng, Haobo Ren"
date: "October-02-2024"
output:
  pdf_document:
    citation_package: biblatex
subtitle: 
date-format: long
abstract: 
format: pdf
number-sections: yes
bibliography: references.bib
thanks: 'Code and data are available at: https://github.com/HaoboRrrr/FIFA20_Player_Potential_Rating_Analysis/tree/main'
---

```{r setup, include = FALSE}
# install.packages("kableExtra")
library(tidyverse)
library(knitr)
library(car)
# library(kableExtra)
knitr::opts_chunk$set(fig.pos = 'H', echo = FALSE, message = FALSE, warning = FALSE)
```

```{R}
library(readr)
library(tidyverse)
library(stringr)
library(ggplot2)
library(knitr)
```

```{R import}
set.seed(123)

players_20_raw <- read_csv("../data/raw_data/players_20.csv")
players_20_raw <- players_20_raw %>% filter(player_positions != "GK")

rows_to_keep <- floor(0.3 * nrow(players_20_raw))
sampled_rows <- sample(1:nrow(players_20_raw), size = rows_to_keep)
player_20_reduced <- players_20_raw[sampled_rows, ]


players_20 <- player_20_reduced |> select(
  short_name,
  age,
  height_cm,
  weight_kg, 
  nationality,
  club,
  overall,
  potential,
  value_eur,
  wage_eur,
  player_positions,
  international_reputation,
  skill_moves,
  body_type,
  release_clause_eur,
  player_tags,
  team_position,
  pace,
  shooting,
  passing,
  dribbling,
  defending,
  physic
)
```

```{r}
players_20$Top_country <- ifelse(players_20$nationality %in% c("Belgium", "France", "Brazil","England","Portugal","Spain","Argentina","Uruguay","Mexico"), 
                        "Top_9", 
                        ifelse(players_20$nationality %in% c("Italy", "Croatia","Denmark","Germany","Netherlands","Colombia","Switzerland","Chile","Wales","Poland","Senegal","Sweden"), 
                               "Top_20", 
                               "Other"))


players_20 <- players_20 %>%
  mutate(
    Top_Club = case_when(
      club %in% c(
        "FC Bayern München", "Real Madrid", "FC Barcelona", "Atlético Madrid",
        "Juventus", "Manchester City", "Paris Saint-Germain", "Sevilla FC",
        "Manchester United", "Liverpool"
      ) ~ "Top_10",
      club %in% c(
        "Arsenal", "Shakhtar Donetsk", "Borussia Dortmund", "Tottenham Hotspur",
        "Olympique Lyonnais", "Chelsea", "Roma", "Napoli", "FC Porto", "SL Benfica"
      ) ~ "Top_20",
      club %in% c(
        "Ajax", "Bayer 04 Leverkusen", "FC Basel 1893", "Villarreal CF",
        "Dynamo Kyiv", "Valencia CF", "Beşiktaş JK", "FC Red Bull Salzburg",
        "Sporting CP", "RB Leipzig"
      ) ~ "Top_30",
      TRUE ~ "other"
    )
  )
players_20 <- players_20 %>%
  mutate(
    is_sub = case_when(
      team_position %in% c('SUB', 'RES') ~ 1,
      TRUE ~ 0
    )
  )
players_20$release_clause_eur[is.na(players_20$release_clause_eur)] <- 0

```


```{R}

players_20$number_tags_proc <- str_count(players_20$player_tags, ",")
players_20$number_tags <- ifelse(players_20$number_tags_proc == 0,0,players_20$number_tags_proc + 1)

players_20$number_tags_proc <- NULL

players_20$number_tags[is.na(players_20$number_tags)] <- 0
players_20$player_positions <- sub(",.*","",players_20$player_positions)

```


# Contributions

Yizhuo Liu: Data cleaning, Introduction, Poster \newline
Leo Cheng: Methods, Results \newline
Haobo Ren: Conclusions & Limitations \newline

# Introduction

In the long history of soccer, there have been many ways of evaluating the performance of soccer players such the number of goals, but these methods only favor a certain kind of player. Knowing this, the video game franchise FIFA comes to mind, which rates players annually on a 0-100 scale based on the previous performance.  However, no one knows what factors influence the rating from FIFA. Therefore, the main objective of this report and the research question is going to be "What factors influence the overall rating of soccer players in tshe FIFA video game". By accomplishing this, we can use it to make real-world predictions. We proposed a hypothesis: the factors "wage", "international reputation", "age", "whether substitution", "club", "value in EUR", "height", "weight" and "release clause in EUR" will affect the response variable - FIFA overall rating. These variables are chosen to be our predictors in the preliminary model. To back up our hypothesis, the research on predicting value of foorball player (Al-Asadi and Tasdemır, 2022) utilizes FIFA for a data-driven approach to player evaluation, which uses very similar predictors and a linear regression base model. In addition, in Pappalardo et al., 2019, they use real-world data to quantify players' performance with a reasonable success. Last but not least, the article Arndt and Brefeld, 2016, uses a combination of linear regression and multitask regression to evaluate current player performance and predict the outcome of a soccer game. The appearance of linear regression model in literature combined with our scatter plot for our response variables and predictions (c.f. Appendix, Figure 4) suggest using a linear regression model to accurately predict the overall rating. 

# Methods

We outline our methods as follows: First, we check the linear assumption for each of our predictors. Second, we fit our preliminary model and plot the corresponding diagrams to address the potential problem of our preliminary model. Third, we use the diagrams plotted to decide whether to perform transformations or add interaction terms to the preliminary model. Fourth, on the newly developed model we will perform a hypothesis test to test the significance of the coefficients as well as AIC backward selection. Finally, we will validate our model using VIF multicollinearity and Cook’s distance and address our research question. The following sections give a detailed explanation. 

## Linear Assumption Check

We use residuals against fitted values scatter plot to check linearity, independence of error, and constant variance assumptions. 

- Curves or trends suggest non-linearity; Box-Cox transformation is applied.

- Residual clustering indicates dependence issues; we add interaction terms.

- Funnel-shaped residuals suggest heteroscedasticity; we use Box-Cox transformation.

After the check, the residuals will randomly scatter around 0 and show no pattern. Lastly, on the Q-Q plot, residual points deviating from the diagonal line suggest violation of the normal error assumption. If this is the case, we apply power transformation on the response variable.

## Hypothesis Test & Variable Selection

t-test and F-test can be used to further check and improve our model. First of all, T-test is used to determine whether individual predictors in the model are statistically significant in explaining dependent variables. To begin with, we choose our null and alternative hypothesis $H_0:\beta=0$, $H_1:\beta\neq0$. Then, we conduct a t-test on each predictor, we get p-values for each predictor and if the p-value is smaller than 0.05, our chosen significant level, reject $H_0$. Otherwise, drop the variable along with all interaction terms containing it. For categorical predictors, we will drop all terms. After the t-test, the F test evaluates whether the independent variables, as a group, explain a significant portion of the variation in the dependent variable. If the F-test fails, we need to reconsider our preliminary model and choose a new one. 


## Validations and Interpretations
After we get the final model, we will validate our model. The first step is to check whether there exists multicollinearity between predictors by using variance inflation factor (VIF). If the VIF for some predictor is too big, showing that this variable has a high collinear relationship with others, we will drop the predictor and get a new model. 
Next, we will check which data points are influential using the Cook’s distance. After choosing a threshold, we will drop all extreme data points and fit a more robust model. 
The final step is to perform backward selection along with AIC (Akaike criterion) to choose our final model with the most effective predictors. The final model can answer our research question by telling us which predictors have the greatest effect on the overall rating by comparing the relative magnitude of the coefficient, and what is the linear relationship after performing transformation on the dataset. We will calculate the confidence interval and interpret the most impactful predictor. 

# Results
Our model is fitted following the methods described above, and we will discuss our results in each of the subsections. Throughout, we will denote our model at different stages with $M_i$. 

## Linear Assumptions 
The preliminary model we fit on the initial predictors introduced in the introduction is denoted as $M_0$ and is shown in Table 2. The following chart shows the comparison of the original series of graphs of assumption checks and transformed graphs. First of all, we drop weight and height since those two variables does not exhibit any linearity with other variables (c.f. appendix, Figure. ). 

The results of the assumption checks before and after applying the Box-Cox transformations demonstrate significant improvements in meeting the linear regression assumptions. Prior to transformation, the residuals versus fitted values plot showed clear patterns, indicating non-linearity and heteroscedasticity. Besides, the Q-Q plot revealed deviations from the diagonal line, particularly at the tails, suggesting non-normal residuals. Using the exact Box-Cox lambda values for the response variable ($\lambda= 2.4$) and predictors (e.g., $\lambda = 0.4646$ for age, $\lambda = 2$ for value and wage), $overall$, $age$, $wage$, $value$ and $release$ are transformed to $overall^{2.4}$, $(age^0.465-1)/0.465$, $wage^{3.7}$, $value^{5.1}$ and $release^8$ respectively. 
After the transformations, the residuals versus fitted values plot almost exhibits a random scatter around the horizontal axis, resolving the earlier patterns and indicating that both linearity and homoscedasticity have been addressed. Similarly, the Q-Q plot shows the residuals closely following the diagonal line, reflecting a significant improvement in the normality of residuals. These results confirm that the exact power transformations have successfully aligned the data with the assumptions of linear regression, enhancing the model's reliability. The transformed model $M_1$ is shown in the table. 

```{R}

fit_rating = lm(overall ~ age + wage_eur +international_reputation + is_sub 
                          + Top_Club + value_eur+ height_cm + weight_kg + release_clause_eur
                          , data = players_20)
fitted_value = fitted(fit_rating)

```

```{r, fig.height=4, fig.width=16, fig.cap="\\label{fig:figs}The reponse v.s. fitted (left), residual v.s. fitted (middle) and Q-Q plot (right) of our preliminary model $M_0$"}
par(mfrow=c(1,3))
plot(fitted_value,players_20$overall, xlim=c(50,100))
abline(0, 1, col='blue')
residual = resid(fit_rating)
plot(fitted_value, residual, xlim=c(50, 85))
plot(fit_rating, which = 2)
```

## Variable Selections
### t-Test and F-test
We performed t-Test and F-test on our predictors. According to Table 1, all of the predictors have a very small p-value except for predictor value_eur, therefore rejecting the null hypothesis for all predictors but value_eur. So we are keeping all the existing predictors minus value_eur and its interaction term. This means the majority of our predictors are statistically significant in explaining the overall rating. This gives us a new model $M_2$ After fixing our predictors, we have done a F-test to determine the overall significance of the regression model. All of our predictors left have a high F value and as a group, which shows that our model successfully rejects the null hypothesis. This confirms that the model as a whole explains a significant portion of the variability in the data. So all of our predictors except value_eur are factors that may potentially influence overall rating in FIFA2020 according to t-test and F-test. 

```{r}
# Transformation
players_20$age_tran <- (players_20$age^0.4646465  - 1) / 0.4646465 
players_20$value_tran <- (players_20$value_eur)^8
players_20$release_tran <- (players_20$release_clause_eur)^5.1
players_20$wage_tran <- (players_20$wage_eur)^3.7

players_20$overall_transformed <- (players_20$overall)^2.4

fit_rating_final= lm(overall_transformed  ~ age_tran + wage_tran +international_reputation + is_sub 
                          + Top_Club + value_tran + release_tran + value_tran:release_tran + age_tran:value_tran
                     + value_tran:wage_tran
                          , data = players_20)
anova_table <- anova(fit_rating_final)
kable(anova_table, caption = "The ANOVA table of performing t-test and F-test.")
```


### Backward selection - AIC
The backward selection using AIC criteria gives an unchanged model. The model starts with an AIC of 15460. Wage is dropped using backward selection since dropping them will result in a lower AIC. This gives us the model $M_3$. 

## Validations
We checked if there is any relationship between our predictors, as well as what datapoint may influence our model prediction a lot to validate the effect of our linear model. 

### Multicollinearity
We calculate the VIF for each predictor. We regard predictors with VIF greater than 5 as the multicollinear variable showing an explosion of variance, except for the inherently multicollinear interaction term. The result is that we have dropped the variable release since it has a VIF of 157, and give us the new model $M_4$. Other variables except for the interaction term and variable involved in the interaction term have a VIF below threshold. 

### Influential points
The Cook’s distance is shown in the diagram below. There are several points that are very outstanding on the diagram. We use the cutoff rule of $\frac{4}{n}$, where $n$ is the number of observations we have. In this case, the cutoff is $8.33\times 10^{-4}$. These outliers are the values that significantly affect our inference on the coefficients since some of them are not representative enough for other players. For example, the player with the highest Cook’s distance is L. Messi, who deviates significantly from other players. Therefore, we remove them and refit the model to make the model more robust. The refitted model is $M_5$. 

```{r, fig.height=4, fig.width=16, fig.cap="\\label{fig:figs} The Cook's distance of model $M_4$. Note that there are many extreme observations in our 4800 observations. The red horizontal line shows the cutoff we use. We will drop all data points above the cutoff line and fit the new model agian." }

fit_rating_final= lm(overall_transformed  ~ age_tran + international_reputation + is_sub 
                          + Top_Club + value_tran + wage_tran
                          , data = players_20)

reduced_fit = step (fit_rating_final , direction = "backward" , k = 2, trace = 0)
cooks_dist <- cooks.distance(reduced_fit)
plot(cooks_dist, type = "h", main = "Cook's Distance", ylab = "Cook's Distance")
abline(h = 4 / length(cooks_dist), col = "red", lty = 2)

influential_points <- which(cooks_dist > 4 / length(cooks_dist))
cleaned_data <- players_20[-influential_points, ]
fit_after_cooks= lm(overall_transformed  ~ age_tran + international_reputation + is_sub 
                          + Top_Club  
                          , data = cleaned_data)

```

### Model Scoring and Assumption Check
The model has residual standard error=624.6, $R^2=0.472$ value and adjusted $R^2=0.471$. These are our  criterions for assessing the model. We also plot the final response v.s. fitted value plot and other residual plots in Figure. 3. The final plot basically meets all our expectations on linear assumption as stated above, with a minor violation for the residual v.s. fitted plot, which will be discussed in the Conclusions section. After this, we get our final model $M_5$. 

```{r, fig.height=4, fig.width=16, fig.cap="\\label{fig:figs} The reponse v.s. fitted (left), residual v.s. fitted (middle) and Q-Q plot (right) of our final model $M_1$. We can see that compare to Fig. 1, all plots are improved in the sense of assumption checking discussed in the paragraph. "}
par(mfrow=c(1,3))

fitted_value_better = fitted(fit_after_cooks)
plot(fitted_value_better,cleaned_data$overall_transformed)
abline(0, 1, col='blue')
model_5_1 <- recordPlot()
residual = resid(fit_after_cooks)
plot(fitted_value_better, residual)
model_5_2 <- recordPlot()
plot(fit_rating_final, which = 2)
model_5_3 <- recordPlot()
```


```{R}
# Load knitr
library(knitr)

# Create the data
data <- data.frame(
  Model = c("$M_0$", "$M_1$", "$M_2$", "$M_3$", "$M_4$", "$M_5$ (final)"),
  Formula = c(
    "overall = 56.442 + 0.549 * age + 0 * wage_eur + -0.32 * international_reputation + -2.08 * is_sub + -2.126 * Top_ClubTop_10 + 3.341 * Top_ClubTop_20 + 3.264 * Top_ClubTop_30 + 0 * value_eur + -0.053 * height_cm + 0.074 * weight_kg + 0 * release_clause_eur ",
    "overall = 1129.482 + 368.482 * age_tran + 0 * wage_tran + 724.868 * international_reputation + -451.703 * is_sub + 1091.352 * Top_ClubTop_10 + 943.987 * Top_ClubTop_20 + 940.517 * Top_ClubTop_30 + 0 * value_tran + 0 * release_tran + 0 * value_tran:release_tran + 0 * age_tran:value_tran + 0 * wage_tran:value_tran",
    "overall = 1129.482 + 368.482 * age_tran + 0 * wage_tran + 724.868 * international_reputation + -451.703 * is_sub + 1091.352 * Top_ClubTop_10 + 943.987 * Top_ClubTop_20 + 940.517 * Top_ClubTop_30 + 0 * release_tran",
    "overall = 1139.68 + 367.313 * age_tran + 725.527 * international_reputation + -455.116 * is_sub + 1131.296 * Top_ClubTop_10 + 958.418 * Top_ClubTop_20 + 950.124 * Top_ClubTop_30 + 0 * release_tran",
    "overall = 1139.68 + 367.313 * age_tran + 725.527 * international_reputation + -455.116 * is_sub + 1131.296 * Top_ClubTop_10 + 958.418 * Top_ClubTop_20 + 950.124 * Top_ClubTop_30",
    "overall = 831.556 + 396.197 * age_tran + 796.439 * international_reputation + -424.303 * is_sub + 971.125 * Top_ClubTop_10 + 998.555 * Top_ClubTop_20 + 972.84 * Top_ClubTop_30"
  )
)

kable(data, caption = "A summary of all regression models we developed from $M_0$ to $M_4$. Except for $M_0$, all $overall$ refers to overall$^{2.4}$. age_trans=age$^2$, value_tran=value_eur$^8$, release_tran=release_clause_eur$^{5.1}$, wage_tran=wage_eur$^{3.7}$. ")
```

# Conclusions
After all the process of assumption checks, variable selections and validations, we arrive at our final model. The term with the highest coefficient is the categorical variable Top Club with level top 20. Among the others, the most important variables are age and international reputation. This gives us a direct answer to the research question: the factors that influence the overall rating the most are the clubs the players are in, the age of the player and the international reputation. 

Take the most impactful variable Top Club as an example, we can interpret it as: if a player has all other predictors fixed and its club changes from the quantile above 30 to the top 20 club, then its average overall rating^2.4 will increase by 998 (i.e. the average overall rating increases by 17.77). Also, we have a 95% confidence to conclude that the true coefficient is between 816 and 1181 since if we were to repeatedly randomly sample from the population and compute a 95% confidence interval, then 95% of the intervals would include the true coefficient. This shows that the club a player is in is very important in predicting the overall rating, namely a higher ranking club will result in a much higher rating than the others. 

Another surprising observation is that age is a very important factor in predicting a player’s overall rating in our model compared to literature, (Al-Asadi and Tasdemır, 2022). 

The overall model meets our expectation on accuracy (reaching a $R^2$ of 0.472) and on linear assumptions. However, due to the complexity of the dataset, there are still limitations for this model. First of all, there are still assumption violations. The residual v.s. fitted model shows a slightly converging trend, which may imply a violation of homoscedasticity. In addition, extreme observations are common due to the nature of soccer players, shown in Figure 2. The model is still sensitive to extreme values. The third problem is on the dataset itself. Our ultimate goal is to quantify and predict a player’s performance. Since the dataset is collected from a video game, there may be bias and may not reflect the real-world scenario. This may be fixed by combining some real-world data with the synthetic one. 

\begin{thebibliography}{99}

\bibitem{al2022predict}
Al-Asadi, M. A., \& Tasdemir, S. (2022). Predict the value of football players using FIFA video game data and machine learning techniques. \textit{IEEE Access}, 10, 22631--22645. IEEE. https://doi.org/10.1109/ACCESS.2022.3166783

\bibitem{pappalardo2019playerank}
Pappalardo, L., Cintia, P., Ferragina, P., Massucco, E., Pedreschi, D., \& Giannotti, F. (2019). PlayeRank: Data-driven performance evaluation and player ranking in soccer via a machine learning approach. \textit{ACM Transactions on Intelligent Systems and Technology (TIST)}, 10(5), 1--27. ACM New York, NY, USA. https://doi.org/10.1145/3129329

\bibitem{arndt2016predicting}
Arndt, C., \& Brefeld, U. (2016). Predicting the future performance of soccer players. \textit{Statistical Analysis and Data Mining: The ASA Data Science Journal}, 9(5), 373--382. Wiley Online Library. https://doi.org/10.1002/sam.11328

\end{thebibliography}

# Appendix
We will include one figure in this section. 

```{r, fig.height=10, fig.width=16, fig.cap="\\label{fig:figs} The response v.s. predictor and predictor v.s. predictor diagram. We can infer linearity from inspecting the relationship between different predictors and response. "}
data <- read.csv("../data/cleaned_data/cleaned_data.csv")
par ( mfrow = c (1, 2) )
# plot(data[, c(2,3,4,5,6)], main="Response against predictors")

# plot(data[, c(2,7,8,9,10,11)], main="Response against predictors")

plot(data[, c(2,3,4,5,6,7,8,9,10,11)], main="Response against predictors")
```
